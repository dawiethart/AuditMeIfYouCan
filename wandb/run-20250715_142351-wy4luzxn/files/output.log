Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[INFO] Group mapping used: {'black': 0, 'white': 1}
Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4044.99 examples/s]
[INFO] Group mapping used: {'black': 0, 'white': 1}
Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 3330.29 examples/s]
No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
{'train_runtime': 0.9224, 'train_samples_per_second': 325.235, 'train_steps_per_second': 6.505, 'train_loss': 0.062228371699651085, 'epoch': 3.0}

=== Iteration 1 ===
[INFO] Group mapping used: {'black': 0, 'white': 1}
Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 3655.64 examples/s]
Casting the dataset: 100%|███████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 403690.51 examples/s]
Lambda: 0.0000, Violation: -0.4988
[Epoch 1, Batch 1/157] Loss: -0.0166, Violation: -0.4988
Lambda: 0.0000, Violation: -0.4985
[Epoch 1, Batch 157/157] Loss: -0.0374, Violation: -0.4985
Lambda: 0.0000, Violation: -0.4985
[Epoch 2, Batch 1/157] Loss: -0.0232, Violation: -0.4985
Lambda: 0.0000, Violation: -0.4923
[Epoch 2, Batch 157/157] Loss: nan, Violation: -0.4923
Lambda: 0.0000, Violation: -0.4918
[Epoch 3, Batch 1/157] Loss: -0.1527, Violation: -0.4918
Lambda: 0.0000, Violation: -0.4774
[Epoch 3, Batch 157/157] Loss: -0.2989, Violation: -0.4774
Training done for C-ERM
Start Calculation of AUC on whole D -> might take a while
Traceback (most recent call last):
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/main.py", line 55, in <module>
    main()
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/main.py", line 51, in main
    runner.run()
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/audit_run.py", line 142, in run
    T = self.refine_until_converged(surrogate, tokenizer, base_model, inputs_D, df_D_mapped, S)
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/audit_run.py", line 68, in refine_until_converged
    delta1, eval_h1 = eval_h(
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/optimization.py", line 41, in eval_h
    pred_h = compute_group_auc_diff_fn(h, inputs_D, df_D)
  File "/home/copresence/miniconda3/envs/ENV/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/surrogate_model.py", line 81, in compute_group_auc_difference
    groups = torch.tensor(dataset["group"].values).to(device)
TypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.
Traceback (most recent call last):
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/main.py", line 55, in <module>
    main()
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/main.py", line 51, in main
    runner.run()
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/audit_run.py", line 142, in run
    T = self.refine_until_converged(surrogate, tokenizer, base_model, inputs_D, df_D_mapped, S)
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/audit_run.py", line 68, in refine_until_converged
    delta1, eval_h1 = eval_h(
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/optimization.py", line 41, in eval_h
    pred_h = compute_group_auc_diff_fn(h, inputs_D, df_D)
  File "/home/copresence/miniconda3/envs/ENV/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/surrogate_model.py", line 81, in compute_group_auc_difference
    groups = torch.tensor(dataset["group"].values).to(device)
TypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.
