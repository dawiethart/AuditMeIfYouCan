Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[INFO] Group mapping used: {'black': 0, 'white': 1}
Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4047.52 examples/s]
[INFO] Group mapping used: {'black': 0, 'white': 1}
Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 3968.72 examples/s]
No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
{'train_runtime': 1.5415, 'train_samples_per_second': 194.619, 'train_steps_per_second': 13.623, 'train_loss': 0.046781006313505624, 'epoch': 3.0}

=== Iteration 1 ===
[INFO] Group mapping used: {}
Casting the dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 393735.24 examples/s]
Traceback (most recent call last):
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/main.py", line 55, in <module>
    main()
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/main.py", line 51, in main
    runner.run()
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/audit_run.py", line 147, in run
    T, surrogate = self.refine_until_converged(
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/audit_run.py", line 68, in refine_until_converged
    delta1, eval_h1 = eval_h(
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/optimization.py", line 27, in eval_h
    h = train_cerm_pairwise(
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/optimization.py", line 170, in train_cerm_pairwise
    "input_ids": torch.tensor(df_T_mapped["input_ids"]).long(),
  File "/home/copresence/miniconda3/envs/ENV/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
  File "/home/copresence/miniconda3/envs/ENV/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2761, in _getitem
    pa_subtable = query_table(self._data, key, indices=self._indices)
  File "/home/copresence/miniconda3/envs/ENV/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 604, in query_table
    _check_valid_column_key(key, table.column_names)
  File "/home/copresence/miniconda3/envs/ENV/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 541, in _check_valid_column_key
    raise KeyError(f"Column {key} not in the dataset. Current columns in the dataset: {columns}")
KeyError: "Column input_ids not in the dataset. Current columns in the dataset: ['id', 'text', 'group', 'true_label', 'weights', 'labels']"
Traceback (most recent call last):
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/main.py", line 55, in <module>
    main()
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/main.py", line 51, in main
    runner.run()
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/audit_run.py", line 147, in run
    T, surrogate = self.refine_until_converged(
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/audit_run.py", line 68, in refine_until_converged
    delta1, eval_h1 = eval_h(
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/optimization.py", line 27, in eval_h
    h = train_cerm_pairwise(
  File "/mnt/sda/david/activeAuditing/new_activeAuditing/AcitveAuditing_140725_refactored/optimization.py", line 170, in train_cerm_pairwise
    "input_ids": torch.tensor(df_T_mapped["input_ids"]).long(),
  File "/home/copresence/miniconda3/envs/ENV/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
  File "/home/copresence/miniconda3/envs/ENV/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2761, in _getitem
    pa_subtable = query_table(self._data, key, indices=self._indices)
  File "/home/copresence/miniconda3/envs/ENV/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 604, in query_table
    _check_valid_column_key(key, table.column_names)
  File "/home/copresence/miniconda3/envs/ENV/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 541, in _check_valid_column_key
    raise KeyError(f"Column {key} not in the dataset. Current columns in the dataset: {columns}")
KeyError: "Column input_ids not in the dataset. Current columns in the dataset: ['id', 'text', 'group', 'true_label', 'weights', 'labels']"
